"""
Gradio-based visualization demo for AI Memory System.

Features:
- Left panel: Real-time memory display (episodic + semantic)
- Right panel: Chat interface
- Memory consolidation with progress display
- Scheduled consolidation support
"""

import gradio as gr
import time
import json
import threading
from datetime import datetime
from typing import List, Dict, Any, Tuple, Optional
import sys
import os

# Add parent directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.memory_system import Memory, MemoryConfig, MemoryRecord, ConsolidationStats


class MemoryDemoApp:
    """Main demo application class."""
    
    def __init__(self):
        """Initialize the demo application."""
        self.memory: Optional[Memory] = None
        self.current_user_id: str = "demo_user"
        self.chat_history: List[Tuple[str, str]] = []
        self.consolidation_log: List[str] = []
        self.is_consolidating: bool = False
        self.scheduled_task: Optional[threading.Timer] = None
        
    def initialize_memory_system(self, user_id: str) -> str:
        """Initialize or reinitialize the memory system."""
        try:
            if not user_id.strip():
                user_id = "demo_user"
            self.current_user_id = user_id.strip()
            
            config = MemoryConfig()
            config.collection_name = f"demo_memories_{self.current_user_id}"
            self.memory = Memory(config)
            self.chat_history = []
            self.consolidation_log = []
            
            return f"âœ… è®°å¿†ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸï¼ç”¨æˆ·ID: {self.current_user_id}"
        except Exception as e:
            return f"âŒ åˆå§‹åŒ–å¤±è´¥: {str(e)}"
    
    def get_all_memories(self) -> str:
        """Get all memories for current user and format as display text."""
        if not self.memory:
            return "âš ï¸ è¯·å…ˆåˆå§‹åŒ–è®°å¿†ç³»ç»Ÿ"
        
        try:
            # Query episodic memories
            episodic = self.memory._store.query(
                filter_expr=f'user_id == "{self.current_user_id}" and memory_type == "episodic"',
                output_fields=["id", "text", "hit_count", "ts", "metadata"],
                limit=100
            )
            
            # Query semantic memories
            semantic = self.memory._store.query(
                filter_expr=f'user_id == "{self.current_user_id}" and memory_type == "semantic"',
                output_fields=["id", "text", "hit_count", "ts", "metadata"],
                limit=100
            )
            
            output = []
            output.append(f"ğŸ“Š è®°å¿†ç»Ÿè®¡ - ç”¨æˆ·: {self.current_user_id}")
            output.append(f"{'='*50}")
            output.append(f"æƒ…æ™¯è®°å¿†: {len(episodic)} æ¡ | è¯­ä¹‰è®°å¿†: {len(semantic)} æ¡")
            output.append("")
            
            # Display episodic memories
            output.append("ğŸ¬ æƒ…æ™¯è®°å¿† (Episodic)")
            output.append("-" * 40)
            if episodic:
                for mem in sorted(episodic, key=lambda x: x.get("ts", 0), reverse=True):
                    ts = mem.get("ts", 0)
                    time_str = datetime.fromtimestamp(ts).strftime("%Y-%m-%d %H:%M") if ts else "N/A"
                    hit = mem.get("hit_count", 0)
                    text = mem.get("text", "")[:80]
                    metadata = mem.get("metadata", {})
                    context = metadata.get("context", "")[:30]
                    output.append(f"[ID:{mem.get('id')}] ğŸ•{time_str} ğŸ’«{hit}æ¬¡")
                    output.append(f"  ğŸ“ {text}...")
                    if context:
                        output.append(f"  ğŸ“ {context}")
                    output.append("")
            else:
                output.append("  (æš‚æ— æƒ…æ™¯è®°å¿†)")
                output.append("")
            
            # Display semantic memories
            output.append("ğŸ§  è¯­ä¹‰è®°å¿† (Semantic)")
            output.append("-" * 40)
            if semantic:
                for mem in sorted(semantic, key=lambda x: x.get("ts", 0), reverse=True):
                    ts = mem.get("ts", 0)
                    time_str = datetime.fromtimestamp(ts).strftime("%Y-%m-%d %H:%M") if ts else "N/A"
                    hit = mem.get("hit_count", 0)
                    metadata = mem.get("metadata", {})
                    fact = metadata.get("fact", mem.get("text", ""))[:80]
                    output.append(f"[ID:{mem.get('id')}] ğŸ•{time_str} ğŸ’«{hit}æ¬¡")
                    output.append(f"  ğŸ’¡ {fact}")
                    output.append("")
            else:
                output.append("  (æš‚æ— è¯­ä¹‰è®°å¿†)")
            
            return "\n".join(output)
            
        except Exception as e:
            return f"âŒ è·å–è®°å¿†å¤±è´¥: {str(e)}"

    def chat(self, message: str, history: List[Tuple[str, str]]) -> Tuple[str, List[Tuple[str, str]], str]:
        """Process chat message and update memories, then call DeepSeek for response."""
        if not self.memory:
            return "", history + [(message, "âš ï¸ è¯·å…ˆåˆå§‹åŒ–è®°å¿†ç³»ç»Ÿ")], self.get_all_memories()
        
        if not message.strip():
            return "", history, self.get_all_memories()
        
        try:
            chat_id = f"chat_{int(time.time())}"
            
            # Add memory from user message
            ids = self.memory.add(
                text=message,
                user_id=self.current_user_id,
                chat_id=chat_id
            )
            
            # Search relevant memories
            results = self.memory.search(
                query=message,
                user_id=self.current_user_id,
                limit=5,
                reconsolidate=True
            )
            
            # Build memory context for LLM
            memory_context = ""
            if results:
                memory_context = "\n\nç›¸å…³è®°å¿†:\n"
                for r in results[:3]:
                    memory_context += f"- {r.text} (ç±»å‹:{r.memory_type})\n"
            
            # Generate response using DeepSeek
            system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªå…·æœ‰é•¿æœŸè®°å¿†èƒ½åŠ›çš„AIåŠ©æ‰‹ã€‚ç”¨æˆ·ID: {self.current_user_id}
è¯·æ ¹æ®ç”¨æˆ·çš„æ¶ˆæ¯å’Œç›¸å…³è®°å¿†æ¥å›ç­”ã€‚å¦‚æœæœ‰ç›¸å…³è®°å¿†ï¼Œè¯·åœ¨å›ç­”ä¸­ä½“ç°å‡ºä½ è®°ä½äº†ç”¨æˆ·çš„ä¿¡æ¯ã€‚
ä¿æŒå‹å¥½ã€è‡ªç„¶çš„å¯¹è¯é£æ ¼ã€‚
{memory_context if memory_context else "å½“å‰æ— ç›¸å…³è®°å¿†"}"""
            
            try:
                ai_response = self.memory._llm_client.chat(system_prompt, message)
            except Exception as llm_error:
                ai_response = f"æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•ç”Ÿæˆå›å¤ã€‚é”™è¯¯: {str(llm_error)}"
            
            # Add memory status info
            if ids:
                memory_status = f"\n\nğŸ’¾ å·²è®°å½•æ­¤æ¬¡å¯¹è¯"
            else:
                memory_status = "\n\nğŸ’­ æ­¤æ¬¡å¯¹è¯æœªè§¦å‘è®°å¿†å­˜å‚¨"
            
            final_response = ai_response + memory_status
            new_history = history + [(message, final_response)]
            return "", new_history, self.get_all_memories()
            
        except Exception as e:
            error_msg = f"âŒ å¤„ç†å¤±è´¥: {str(e)}"
            return "", history + [(message, error_msg)], self.get_all_memories()
    
    def run_consolidation(self, progress=gr.Progress()) -> Tuple[str, str]:
        """Run memory consolidation with progress updates."""
        if not self.memory:
            return "âš ï¸ è¯·å…ˆåˆå§‹åŒ–è®°å¿†ç³»ç»Ÿ", self.get_all_memories()
        
        if self.is_consolidating:
            return "â³ å·©å›ºä»»åŠ¡æ­£åœ¨è¿›è¡Œä¸­...", self.get_all_memories()
        
        self.is_consolidating = True
        self.consolidation_log = []
        
        try:
            self.consolidation_log.append(f"ğŸš€ å¼€å§‹å·©å›º - {datetime.now().strftime('%H:%M:%S')}")
            progress(0.1, desc="æ­£åœ¨æŸ¥è¯¢è®°å¿†...")
            
            # Run consolidation
            stats = self.memory.consolidate(user_id=self.current_user_id)
            
            progress(0.9, desc="å·©å›ºå®Œæˆ")
            
            # Build result log
            log = []
            log.append(f"âœ… å·©å›ºå®Œæˆ - {datetime.now().strftime('%H:%M:%S')}")
            log.append(f"ğŸ“Š å¤„ç†ç»Ÿè®¡:")
            log.append(f"  - å¤„ç†è®°å¿†æ•°: {stats.memories_processed}")
            log.append(f"  - åˆ›å»ºè¯­ä¹‰æ•°: {stats.semantic_created}")
            
            self.consolidation_log.extend(log)
            progress(1.0, desc="å®Œæˆ")
            
            return "\n".join(self.consolidation_log), self.get_all_memories()
            
        except Exception as e:
            error = f"âŒ å·©å›ºå¤±è´¥: {str(e)}"
            self.consolidation_log.append(error)
            return "\n".join(self.consolidation_log), self.get_all_memories()
        finally:
            self.is_consolidating = False
    
    def reset_memories(self) -> Tuple[str, str]:
        """Reset all memories for current user."""
        if not self.memory:
            return "âš ï¸ è¯·å…ˆåˆå§‹åŒ–è®°å¿†ç³»ç»Ÿ", ""
        
        try:
            count = self.memory.reset(self.current_user_id)
            self.chat_history = []
            return f"âœ… å·²åˆ é™¤ {count} æ¡è®°å¿†", self.get_all_memories()
        except Exception as e:
            return f"âŒ é‡ç½®å¤±è´¥: {str(e)}", self.get_all_memories()


def create_demo_interface():
    """Create and return the Gradio interface."""
    app = MemoryDemoApp()
    
    with gr.Blocks(title="AI Memory System Demo", theme=gr.themes.Soft()) as demo:
        gr.Markdown("# ğŸ§  AI Memory System å¯è§†åŒ–æµ‹è¯•")
        gr.Markdown("åŸºäºè®¤çŸ¥å¿ƒç†å­¦çš„AIé•¿æœŸè®°å¿†ç³»ç»Ÿæ¼”ç¤º")
        
        with gr.Row():
            user_id_input = gr.Textbox(label="ç”¨æˆ·ID", value="demo_user", scale=2)
            init_btn = gr.Button("ğŸ”„ åˆå§‹åŒ–ç³»ç»Ÿ", variant="primary", scale=1)
            init_status = gr.Textbox(label="çŠ¶æ€", interactive=False, scale=2)
        
        with gr.Row():
            # Left panel - Memory display
            with gr.Column(scale=1):
                gr.Markdown("## ğŸ“š è®°å¿†åº“")
                memory_display = gr.Textbox(
                    label="å®æ—¶è®°å¿†çŠ¶æ€",
                    lines=25,
                    max_lines=30,
                    interactive=False
                )
                refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°è®°å¿†", variant="secondary")
                
                gr.Markdown("### âš™ï¸ è®°å¿†å·©å›º")
                consolidate_btn = gr.Button("ğŸ”§ è¿è¡Œå·©å›º", variant="primary")
                consolidation_output = gr.Textbox(label="å·©å›ºæ—¥å¿—", lines=8, interactive=False)
                
                reset_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºè®°å¿†", variant="stop")
                reset_output = gr.Textbox(label="æ“ä½œç»“æœ", lines=2, interactive=False)
            
            # Right panel - Chat interface
            with gr.Column(scale=1):
                gr.Markdown("## ğŸ’¬ å¯¹è¯æµ‹è¯•")
                chatbot = gr.Chatbot(label="å¯¹è¯å†å²", height=400)
                msg_input = gr.Textbox(label="è¾“å…¥æ¶ˆæ¯", placeholder="è¾“å…¥è¦è®°å¿†çš„å†…å®¹...")
                send_btn = gr.Button("å‘é€", variant="primary")
                
                gr.Markdown("### ğŸ’¡ æµ‹è¯•å»ºè®®")
                gr.Markdown("""
                - è¾“å…¥ä¸ªäººä¿¡æ¯: "æˆ‘æ˜¯åŒ—äº¬å¤§å­¦è®¡ç®—æœºä¸“ä¸šçš„å­¦ç”Ÿ"
                - æ˜ç¡®è®°å¿†è¯·æ±‚: "è¯·è®°ä½æˆ‘å–œæ¬¢å–å’–å•¡"
                - é¡¹ç›®ä¿¡æ¯: "æˆ‘æ­£åœ¨å¼€å‘ä¸€ä¸ªAIè®°å¿†ç³»ç»Ÿ"
                - é—²èŠæµ‹è¯•: "ä½ å¥½" (ä¸ä¼šè¢«è®°å½•)
                """)
        
        # Event handlers
        init_btn.click(
            fn=app.initialize_memory_system,
            inputs=[user_id_input],
            outputs=[init_status]
        ).then(
            fn=app.get_all_memories,
            outputs=[memory_display]
        )
        
        refresh_btn.click(fn=app.get_all_memories, outputs=[memory_display])
        
        send_btn.click(
            fn=app.chat,
            inputs=[msg_input, chatbot],
            outputs=[msg_input, chatbot, memory_display]
        )
        
        msg_input.submit(
            fn=app.chat,
            inputs=[msg_input, chatbot],
            outputs=[msg_input, chatbot, memory_display]
        )
        
        consolidate_btn.click(
            fn=app.run_consolidation,
            outputs=[consolidation_output, memory_display]
        )
        
        reset_btn.click(
            fn=app.reset_memories,
            outputs=[reset_output, memory_display]
        )
    
    return demo


if __name__ == "__main__":
    demo = create_demo_interface()
    demo.launch(server_name="0.0.0.0", server_port=7860, share=False)
