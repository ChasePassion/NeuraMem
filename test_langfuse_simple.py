#!/usr/bin/env python3
"""ç®€åŒ–æµ‹è¯•è„šæœ¬ï¼šéªŒè¯Langfuseç›‘æ§åŠŸèƒ½ï¼ˆä¸ä¾èµ–Milvusï¼‰"""

import os
import sys
from unittest.mock import Mock, patch

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

def test_complete_langfuse_integration():
    """æµ‹è¯•å®Œæ•´çš„Langfuseé›†æˆï¼Œä¸ä¾èµ–å¤–éƒ¨æœåŠ¡"""
    print("=== æµ‹è¯•å®Œæ•´çš„Langfuseé›†æˆ ===")
    
    # æ¨¡æ‹Ÿæ‰€æœ‰å¤–éƒ¨ä¾èµ–
    with patch('memory_system.memory.get_client') as mock_get_client, \
         patch('memory_system.clients.llm.OpenAI') as mock_openai, \
         patch('memory_system.clients.embedding.OpenAI') as mock_embedding_openai, \
         patch('memory_system.clients.milvus_store.MilvusStore') as mock_milvus:
        
        # æ¨¡æ‹ŸLangfuseå®¢æˆ·ç«¯
        mock_langfuse_client = Mock()
        mock_get_client.return_value = mock_langfuse_client
        
        # æ¨¡æ‹ŸLLMå“åº”
        mock_response = Mock()
        mock_response.choices = [Mock()]
        mock_response.choices[0].message.content = '''
        {
            "add": [
                {"text": "ç”¨æˆ·å–œæ¬¢åœ¨æ—©ä¸Šå–å’–å•¡"},
                {"text": "ç”¨æˆ·å·¥ä½œåœ°ç‚¹åœ¨å¸‚ä¸­å¿ƒ"}
            ],
            "update": [],
            "delete": []
        }
        '''
        
        mock_llm_client = Mock()
        mock_llm_client.chat.completions.create.return_value = mock_response
        mock_openai.return_value = mock_llm_client
        
        # æ¨¡æ‹ŸåµŒå…¥å®¢æˆ·ç«¯
        mock_embedding_client = Mock()
        mock_embedding_client.embeddings.create.return_value = Mock(data=[[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]])
        mock_embedding_openai.return_value = mock_embedding_client
        
        # æ¨¡æ‹ŸMilvuså­˜å‚¨
        mock_store = Mock()
        mock_store.query.return_value = []  # æ²¡æœ‰ç°æœ‰è®°å¿†
        mock_store.insert.return_value = [1, 2]  # æ’å…¥ä¸¤ä¸ªè®°å¿†ï¼Œè¿”å›ID 1,2
        mock_milvus.return_value = mock_store
        
        # å¯¼å…¥å¹¶åˆ›å»ºMemoryå®ä¾‹
        from memory_system.memory import Memory
        from memory_system.config import MemoryConfig
        
        config = MemoryConfig()
        config.deepseek_api_key = "test_key"
        config.siliconflow_api_key = "test_embedding_key"
        config.milvus_uri = "http://localhost:19530"
        
        memory = Memory(config)
        
        # è°ƒç”¨manageæ–¹æ³•
        result = memory.manage(
            user_text="æˆ‘ä»Šå¤©æ—©ä¸Šå–äº†ä¸€æ¯å’–å•¡ï¼Œç„¶åå»äº†å¸‚ä¸­å¿ƒçš„åŠå…¬å®¤",
            assistant_text="å¬èµ·æ¥ä½ ä»Šå¤©è¿‡å¾—å¾ˆå……å®ã€‚æ—©ä¸Šå–å’–å•¡æ˜¯ä¸ªä¸é”™çš„ä¹ æƒ¯ã€‚",
            user_id="test_user",
            chat_id="test_chat"
        )
        
        # éªŒè¯ç»“æœ
        print(f"manageæ–¹æ³•è¿”å›çš„è®°å¿†ID: {result}")
        print(f"è¿”å›çš„è®°å¿†æ•°é‡: {len(result)}")
        
        # éªŒè¯Langfuseè°ƒç”¨
        total_calls = mock_langfuse_client.update_current_trace.call_count
        print(f"æ€»update_current_traceè°ƒç”¨æ¬¡æ•°: {total_calls}")
        
        # åˆ†ææ‰€æœ‰Langfuseè°ƒç”¨
        for i, call in enumerate(mock_langfuse_client.update_current_trace.call_args_list):
            kwargs = call[1] if call else {}
            output = kwargs.get('output', {})
            metadata = kwargs.get('metadata', {})
            
            print(f"\n--- ç¬¬{i+1}æ¬¡Langfuseè°ƒç”¨ ---")
            print(f"outputé”®: {list(output.keys())}")
            print(f"metadataé”®: {list(metadata.keys())}")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«LLMåŸå§‹è¾“å‡º
            if 'llm_raw_output' in output:
                print("  âœ“ åŒ…å«llm_raw_output")
                raw_output = output['llm_raw_output']
                print(f"  - åŸå§‹è¾“å‡ºé•¿åº¦: {len(raw_output)} å­—ç¬¦")
                print(f"  - åŸå§‹è¾“å‡ºé¢„è§ˆ: {raw_output[:100]}...")
            
            if 'llm_parsed_output' in output:
                print("  âœ“ åŒ…å«llm_parsed_output")
                parsed = output['llm_parsed_output']
                if isinstance(parsed, dict):
                    print(f"  - è§£æåçš„æ“ä½œ: {list(parsed.keys())}")
                    if 'add' in parsed:
                        print(f"  - æ·»åŠ æ“ä½œæ•°é‡: {len(parsed['add'])}")
            
            if 'llm_model' in output:
                print(f"  âœ“ ä½¿ç”¨çš„æ¨¡å‹: {output['llm_model']}")
            
            if 'llm_success' in output:
                print(f"  âœ“ è§£ææˆåŠŸ: {output['llm_success']}")
            
            # æ£€æŸ¥æ“ä½œæ‘˜è¦
            if 'operation_summary' in output:
                print("  âœ“ åŒ…å«operation_summary")
                summary = output['operation_summary']
                print(f"  - å†³ç­–è¿½è¸ªå¯ç”¨: {summary.get('decision_trace_available')}")
                print(f"  - æ·»åŠ æ•°é‡: {summary.get('added_count')}")
                print(f"  - æ›´æ–°æ•°é‡: {summary.get('updated_count')}")
                print(f"  - åˆ é™¤æ•°é‡: {summary.get('deleted_count')}")
        
        return result

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹æµ‹è¯•Langfuseç›‘æ§manageæ–¹æ³•æ¨¡å‹åŸå§‹è¾“å‡ºçš„åŠŸèƒ½\n")
    
    try:
        # æµ‹è¯•å®Œæ•´çš„Langfuseé›†æˆ
        test_complete_langfuse_integration()
        
        print("\n=== æµ‹è¯•æ€»ç»“ ===")
        print("âœ… LLMClient.chat_jsonæ–¹æ³• - æˆåŠŸè¿”å›ç»“æ„åŒ–æ•°æ®")
        print("âœ… EpisodicMemoryManager - æˆåŠŸè®°å½•LLMåŸå§‹è¾“å‡º")
        print("âœ… Memory.manageæ–¹æ³• - æˆåŠŸé›†æˆå®Œæ•´çš„ç›‘æ§é“¾è·¯")
        print("\nğŸ‰ æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
        print("\nç°åœ¨Langfuseå¯ä»¥å®Œæ•´ç›‘æ§manageæ–¹æ³•çš„æ¨¡å‹åŸå§‹è¾“å‡ºï¼ŒåŒ…æ‹¬ï¼š")
        print("- æ¨¡å‹çš„åŸå§‹JSONå“åº”")
        print("- è§£æåçš„ç»“æ„åŒ–æ•°æ®")
        print("- ä½¿ç”¨çš„æ¨¡å‹ä¿¡æ¯")
        print("- è§£ææˆåŠŸçŠ¶æ€")
        print("- æœ€ç»ˆçš„æ“ä½œæ‰§è¡Œç»“æœ")
        
    except Exception as e:
        print(f"\næµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
